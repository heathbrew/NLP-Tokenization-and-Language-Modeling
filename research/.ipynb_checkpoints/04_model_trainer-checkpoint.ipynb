{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebd17b3d-88ea-4948-b7c8-f8986db449e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d800b78a-03ee-4bd0-b68d-5f22b1804a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Desktop\\\\NLP\\\\Lab 1\\\\NLP-Tokenization-and-Language-Modeling'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "277d5cf0-f6a4-47f3-8171-dd36d4ee3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbe5e2a9-7981-4eb3-9ec9-391f21a607bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Desktop\\\\NLP\\\\Lab 1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad229c02-9acb-4056-b9d1-8e0062b3f0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 22:23:41,400 - INFO - Model training completed\n",
      "2024-01-31 22:23:41,420 - INFO - Unigram Model Saved\n",
      "2024-01-31 22:23:41,516 - INFO - Bigram Model Saved\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    train_file: Path\n",
    "    test_file: Path\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(self):\n",
    "        self.root_dir = Path(\"D:/Desktop/NLP/Lab 1/NLP-Tokenization-and-Language-Modeling\")\n",
    "        self.train_file = self.root_dir / \"dataset/UnzippedAngular/train.txt\"\n",
    "        self.test_file = self.root_dir / \"dataset/UnzippedAngular/test.txt\"\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        return DataTransformationConfig(\n",
    "            root_dir=self.root_dir,\n",
    "            train_file=self.train_file,\n",
    "            test_file=self.test_file,\n",
    "        )\n",
    "\n",
    "# Language Model Functions\n",
    "import spacy\n",
    "\n",
    "# Initialize spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def spacy_tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text.lower() for token in doc if not token.is_punct and not token.is_space]\n",
    "\n",
    "def create_unigram_model(tokens):\n",
    "    return Counter(tokens)\n",
    "\n",
    "def create_bigram_model(tokens):\n",
    "    bigram_model = defaultdict(Counter)\n",
    "    for prev_word, curr_word in zip(tokens[:-1], tokens[1:]):\n",
    "        bigram_model[prev_word][curr_word] += 1\n",
    "    return bigram_model\n",
    "\n",
    "def save_model(model, file_path):\n",
    "    joblib.dump(model, file_path)\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def train_model(self):\n",
    "        with open(self.config.train_file, 'r', encoding='utf-8') as file:\n",
    "            train_text = file.read()\n",
    "\n",
    "        # Use spaCy for tokenization\n",
    "        tokens = spacy_tokenize(train_text.lower())\n",
    "        self.unigram_model = create_unigram_model(tokens)\n",
    "        self.bigram_model = create_bigram_model(tokens)\n",
    "        logging.info(\"Model training completed\")\n",
    "        # Save models\n",
    "        save_model(self.unigram_model, self.config.root_dir / \"Models/unigrammodel.pkl\")\n",
    "        logging.info(\"Unigram Model Saved\")\n",
    "        save_model(self.bigram_model, self.config.root_dir / \"Models/bigrammodel.pkl\")\n",
    "        logging.info(\"Bigram Model Saved\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        config_manager = ConfigurationManager()\n",
    "        data_transformation_config = config_manager.get_data_transformation_config()\n",
    "        data_transformation = DataTransformation(config=data_transformation_config)\n",
    "        \n",
    "        # Train the model using train.txt\n",
    "        data_transformation.train_model()\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error occurred: {e}\")\n",
    "        raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05315bcf-65b6-4616-ada8-ed32f9001aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
